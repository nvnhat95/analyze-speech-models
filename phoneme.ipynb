{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ede6a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 17:42:46 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tqdm\n",
    "import IPython\n",
    "import fairseq\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import utils\n",
    "from fairseq.dataclass.utils import convert_namespace_to_omegaconf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3870cf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models.wav2vec.wav2vec2 import Wav2Vec2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0b51c9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Model(\n",
       "  (feature_extractor): ConvFeatureExtractionModel(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        (3): GELU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "  (dropout_input): Dropout(p=0.1, inplace=False)\n",
       "  (dropout_features): Dropout(p=0.1, inplace=False)\n",
       "  (quantizer): GumbelVectorQuantizer(\n",
       "    (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "  )\n",
       "  (project_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (pos_conv): Sequential(\n",
       "      (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (1): SamePad()\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (final_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_base = torch.load('./pretrained_checkpoints/wav2vec_small.pt')\n",
    "wav2vec2 = Wav2Vec2Model.build_model(convert_namespace_to_omegaconf(checkpoint_base['args']).model, task='audio_pretraining')\n",
    "\n",
    "checkpoint_finetune = torch.load('./pretrained_checkpoints/wav2vec_small_960h.pt')\n",
    "utils.reset_all_weights(wav2vec2)\n",
    "for key in checkpoint_finetune['model']:\n",
    "    if 'w2v_encoder.w2v_model.' == key[:len('w2v_encoder.w2v_model.')]:\n",
    "        checkpoint_base['model'][key[len('w2v_encoder.w2v_model.'):]] = checkpoint_finetune['model'][key]\n",
    "\n",
    "wav2vec2.load_state_dict(checkpoint_base['model'])\n",
    "wav2vec2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea41ec2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "2d78513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2vec2forward(model, source, aggregation=True, hidden_layer=None):\n",
    "    \"\"\"\n",
    "    Inference function of pretrained wav2vec2 to extract intermediate representations\n",
    "    Ref: https://github.com/pytorch/fairseq/blob/89ec6e7efff867d258947acafc57189b257212d0/fairseq/models/wav2vec/wav2vec2.py\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        cnn_features = model.feature_extractor(source)\n",
    "        \n",
    "        cnn_features = cnn_features.transpose(1, 2)\n",
    "        features = model.layer_norm(cnn_features)\n",
    "\n",
    "        if model.quantizer: # this is not None in pretrained w2v\n",
    "            q = model.quantizer(features, produce_targets=False)\n",
    "            quantized_features = q[\"x\"]\n",
    "            projected_quantized_features = model.project_q(quantized_features)\n",
    "\n",
    "        if model.post_extract_proj is not None: # this is not None in pretrained w2v\n",
    "            features = model.post_extract_proj(features)\n",
    "\n",
    "        if model.input_quantizer is not None: # this is None in pretrained w2v\n",
    "            q = model.input_quantizer(features, produce_targets=False)\n",
    "            features = q['x']\n",
    "            features = model.project_inp(features)\n",
    "            \n",
    "        encoder_outputs, encoder_layers_features = model.encoder(features, padding_mask=None, layer=hidden_layer)\n",
    "            \n",
    "        context_vectors = model.final_proj(encoder_outputs)\n",
    "        \n",
    "        ret = dict()\n",
    "        ret['cnn_output'] = cnn_features.squeeze(0)\n",
    "        ret['vq'] = quantized_features.squeeze(0)\n",
    "        ret['projected_vq'] = projected_quantized_features.squeeze(0)\n",
    "        ret['encoder_output'] = encoder_outputs.squeeze(0)\n",
    "        ret['context_vector'] = context_vectors.squeeze(0)\n",
    "        if len(encoder_layers_features) > 0:\n",
    "            ret['encoder_hiddens'] = [h[0][0] for h in encoder_layers_features]\n",
    "        \n",
    "        if aggregation:\n",
    "            ret['cnn_output'] = torch.mean(ret['cnn_output'], dim=0)\n",
    "            ret['vq'] = torch.mean(ret['vq'], dim=0)\n",
    "            ret['projected_vq'] = torch.mean(ret['projected_vq'], dim=0)\n",
    "            ret['encoder_output'] = torch.mean(ret['encoder_output'], dim=0)\n",
    "            ret['context_vector'] = torch.mean(ret['context_vector'], dim=0)\n",
    "            if len(encoder_layers_features) > 0:\n",
    "                ret['encoder_hiddens'] = [torch.mean(h, dim=0) for h in ret['encoder_hiddens']]\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0a8c44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/TIMIT_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d05d3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./outputs/extracted_features/wav2vec2_small/TIMIT_train_word.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4ec607c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File(\"./outputs/extracted_features/wav2vec2_small-random_init/TIMIT_train_word.h5\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33234c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae62cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3989it [53:31,  3.48s/it]"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm.tqdm(df.iterrows()):\n",
    "    wav_id = row['wav_id']\n",
    "    word_path = row['wav_path'][:-7] + 'WRD'\n",
    "    with open(word_path) as f:\n",
    "        words = f.read().strip('\\n').split('\\n')\n",
    "    wav, sr = sf.read(row['wav_path'], dtype='float32')\n",
    "    for j, word in enumerate(words):\n",
    "        word = word.split(' ')\n",
    "#         if word[2] not in valid_words:\n",
    "#             continue\n",
    "        s = wav[int(word[0]):int(word[1])+1]\n",
    "        if len(s) < 400:\n",
    "            s = np.concatenate((s, np.zeros(400-len(s), dtype=np.float32)))\n",
    "        output = wav2vec2forward(wav2vec2, torch.tensor(s).unsqueeze(0), aggregation=True)\n",
    "\n",
    "        hf.create_dataset(f\"{wav_id}-{word[2]}_{j}-cnn_output\", data=output['cnn_output'].cpu())\n",
    "        hf.create_dataset(f\"{wav_id}-{word[2]}_{j}-vq\", data=output['vq'].cpu())\n",
    "        hf.create_dataset(f\"{wav_id}-{word[2]}_{j}-projected_vq\", data=output['projected_vq'].cpu())\n",
    "        hf.create_dataset(f\"{wav_id}-{word[2]}_{j}-encoder_output\", data=output['encoder_output'].cpu())\n",
    "        hf.create_dataset(f\"{wav_id}-{word[2]}_{j}-context_vector\", data=output['context_vector'].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "74ac2ffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26306/2348609373.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{wav_id}-{current_word}_{word_idx}-{p[2]}_{j}-projected_vq\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'projected_vq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{wav_id}-{current_word}_{word_idx}-{p[2]}_{j}-encoder_output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mhf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{wav_id}-{current_word}_{word_idx}-{p[2]}_{j}-context_vector\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'context_vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/h5py/_hl/group.py\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mdsid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_new_dset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mdset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/lib/python3.8/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mdset_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, row in df.iterrows():\n",
    "    wav_id = row['wav_id']\n",
    "    phoneme_path = row['wav_path'][:-7] + 'PHN'\n",
    "    word_path = row['wav_path'][:-7] + 'WRD'\n",
    "    with open(phoneme_path) as f:\n",
    "        phonemes = f.read().strip('\\n').split('\\n')\n",
    "    with open(word_path) as f:\n",
    "        words = f.read().strip('\\n').split('\\n')\n",
    "    wav, sr = sf.read(row['wav_path'], dtype='float32')\n",
    "    word_idx = -1\n",
    "    word_end_pos = -1\n",
    "    if phonemes[0].split(' ')[2] != 'h#':\n",
    "        print(phonemes[0].split(' ')[2])\n",
    "    if phonemes[-1].split(' ')[2] != 'h#':\n",
    "        print(phonemes[-1].split(' ')[2])\n",
    "    for j, p in enumerate(phonemes):\n",
    "        p = p.split(' ')\n",
    "        if p[2] == 'h#':\n",
    "            continue\n",
    "        try:\n",
    "            if int(p[0]) >= word_end_pos:\n",
    "                word_idx += 1\n",
    "                word_end_pos = int(words[word_idx].split(' ')[1])\n",
    "                current_word = words[word_idx].split(' ')[2]\n",
    "        except:\n",
    "            continue\n",
    "        s = wav[int(p[0]):int(p[1])+1]\n",
    "        if len(s) < 400:\n",
    "            s = np.concatenate((s, np.zeros(400-len(s), dtype=np.float32)))\n",
    "        output = wav2vec2forward(wav2vec2, torch.tensor(s).unsqueeze(0), aggregation=True)\n",
    "\n",
    "        hf.create_dataset(f\"{wav_id}-{current_word}_{word_idx}-{p[2]}_{j}-cnn_output\", data=output['cnn_output'].cpu())\n",
    "        hf.create_dataset(f\"{wav_id}-{current_word}_{word_idx}-{p[2]}_{j}-vq\", data=output['vq'].cpu())\n",
    "        hf.create_dataset(f\"{wav_id}-{current_word}_{word_idx}-{p[2]}_{j}-projected_vq\", data=output['projected_vq'].cpu())\n",
    "        hf.create_dataset(f\"{wav_id}-{current_word}_{word_idx}-{p[2]}_{j}-encoder_output\", data=output['encoder_output'].cpu())\n",
    "        hf.create_dataset(f\"{wav_id}-{current_word}_{word_idx}-{p[2]}_{j}-context_vector\", data=output['context_vector'].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0116de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "words_list = defaultdict(int)\n",
    "for i, row in df.iterrows():\n",
    "    wav_id = row['wav_id']\n",
    "    word_path = row['wav_path'][:-7] + 'WRD'\n",
    "    with open(word_path) as f:\n",
    "        words = f.read().strip('\\n').split('\\n')\n",
    "    for w in words:\n",
    "        words_list[w.split(' ')[2]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9a981562",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_word_list = set()\n",
    "for w in words_list:\n",
    "    if words_list[w] >= 7:\n",
    "        valid_word_list.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bb73946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_word_list_test = set()\n",
    "for w in words_list:\n",
    "    if words_list[w] >= 7:\n",
    "        valid_word_list_test.add(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8452af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_words = valid_word_list_test.intersection(valid_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "759d3125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data/TIMIT/valid_words.pkl\", 'wb') as f:\n",
    "    pickle.dump(valid_words, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ab227e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1603,\n",
       " 'to': 1018,\n",
       " 'in': 947,\n",
       " 'a': 867,\n",
       " 'that': 612,\n",
       " 'she': 572,\n",
       " 'an': 571,\n",
       " 'your': 565,\n",
       " 'all': 545,\n",
       " 'had': 526,\n",
       " 'like': 518,\n",
       " 'me': 517,\n",
       " 'and': 492,\n",
       " \"don't\": 488,\n",
       " 'water': 479,\n",
       " 'dark': 473,\n",
       " 'year': 473,\n",
       " 'oily': 470,\n",
       " 'rag': 470,\n",
       " 'wash': 469,\n",
       " 'ask': 464,\n",
       " 'carry': 463,\n",
       " 'suit': 462,\n",
       " 'greasy': 462,\n",
       " 'of': 455,\n",
       " 'is': 401,\n",
       " 'you': 274,\n",
       " 'are': 238,\n",
       " 'was': 236,\n",
       " 'he': 233,\n",
       " 'for': 216,\n",
       " 'his': 190,\n",
       " 'with': 188,\n",
       " 'be': 176,\n",
       " 'it': 171,\n",
       " 'on': 167,\n",
       " 'we': 154,\n",
       " 'this': 152,\n",
       " 'they': 141,\n",
       " 'by': 130,\n",
       " 'her': 127,\n",
       " 'from': 125,\n",
       " 'as': 125,\n",
       " 'have': 124,\n",
       " 'not': 119,\n",
       " 'but': 103,\n",
       " 'will': 100,\n",
       " 'i': 99,\n",
       " 'do': 93,\n",
       " 'him': 84,\n",
       " 'my': 83,\n",
       " 'or': 78,\n",
       " 'no': 76,\n",
       " 'were': 75,\n",
       " 'at': 74,\n",
       " 'can': 73,\n",
       " 'new': 68,\n",
       " 'up': 68,\n",
       " 'would': 67,\n",
       " 'every': 65,\n",
       " 'now': 60,\n",
       " 'our': 60,\n",
       " 'how': 59,\n",
       " 'each': 59,\n",
       " 'their': 58,\n",
       " 'big': 57,\n",
       " 'so': 57,\n",
       " 'often': 56,\n",
       " 'may': 55,\n",
       " 'has': 55,\n",
       " 'out': 55,\n",
       " 'never': 54,\n",
       " 'many': 51,\n",
       " 'into': 51,\n",
       " 'if': 50,\n",
       " 'saw': 50,\n",
       " 'get': 50,\n",
       " 'one': 49,\n",
       " 'more': 47,\n",
       " 'when': 47,\n",
       " 'what': 46,\n",
       " 'did': 46,\n",
       " 'made': 46,\n",
       " 'much': 46,\n",
       " 'could': 45,\n",
       " 'about': 45,\n",
       " 'first': 44,\n",
       " 'both': 44,\n",
       " 'go': 43,\n",
       " 'down': 43,\n",
       " 'them': 43,\n",
       " \"it's\": 43,\n",
       " 'should': 42,\n",
       " 'through': 41,\n",
       " 'only': 41,\n",
       " 'too': 40,\n",
       " 'two': 40,\n",
       " 'there': 39,\n",
       " 'most': 39,\n",
       " 'these': 38,\n",
       " 'must': 38,\n",
       " 'make': 36,\n",
       " 'who': 36,\n",
       " 'movies': 35,\n",
       " 'keep': 35,\n",
       " 'long': 35,\n",
       " 'allow': 35,\n",
       " 'any': 35,\n",
       " 'use': 34,\n",
       " 'good': 34,\n",
       " 'us': 33,\n",
       " 'just': 33,\n",
       " 'some': 32,\n",
       " 'then': 31,\n",
       " 'hot': 31,\n",
       " 'need': 30,\n",
       " 'always': 30,\n",
       " 'over': 30,\n",
       " 'those': 30,\n",
       " 'eat': 29,\n",
       " 'well': 29,\n",
       " 'near': 29,\n",
       " 'caused': 29,\n",
       " 'evening': 29,\n",
       " 'huge': 28,\n",
       " 'used': 28,\n",
       " \"didn't\": 28,\n",
       " 'found': 28,\n",
       " 'seldom': 28,\n",
       " 'cheese': 28,\n",
       " 'please': 28,\n",
       " 'back': 28,\n",
       " 'see': 27,\n",
       " 'hand': 27,\n",
       " 'after': 27,\n",
       " 'than': 27,\n",
       " 'took': 26,\n",
       " 'time': 26,\n",
       " 'said': 26,\n",
       " 'home': 25,\n",
       " 'also': 25,\n",
       " 'enough': 25,\n",
       " 'hard': 25,\n",
       " 'which': 25,\n",
       " 'its': 25,\n",
       " 'does': 25,\n",
       " 'top': 25,\n",
       " 'why': 25,\n",
       " 'gas': 25,\n",
       " 'large': 25,\n",
       " 'needs': 24,\n",
       " 'off': 24,\n",
       " 'cream': 23,\n",
       " 'early': 23,\n",
       " 'rich': 23,\n",
       " 'young': 23,\n",
       " 'high': 23,\n",
       " 'small': 23,\n",
       " 'nothing': 23,\n",
       " 'eyes': 23,\n",
       " 'place': 23,\n",
       " 'help': 22,\n",
       " 'problem': 22,\n",
       " 'great': 22,\n",
       " 'sun': 22,\n",
       " 'pie': 22,\n",
       " 'juice': 22,\n",
       " 'ice': 22,\n",
       " 'look': 22,\n",
       " 'fresh': 22,\n",
       " 'dinner': 22,\n",
       " 'bought': 22,\n",
       " 'been': 21,\n",
       " 'ate': 21,\n",
       " 'know': 21,\n",
       " 'monday': 21,\n",
       " 'orange': 21,\n",
       " 'barely': 21,\n",
       " 'boy': 21,\n",
       " 'else': 21,\n",
       " 'shortage': 21,\n",
       " 'agency': 21,\n",
       " 'another': 21,\n",
       " 'brother': 21,\n",
       " 'garden': 21,\n",
       " 'even': 20,\n",
       " 'other': 20,\n",
       " 'add': 20,\n",
       " 'while': 20,\n",
       " 'money': 19,\n",
       " 'sometimes': 19,\n",
       " 'come': 19,\n",
       " 'away': 19,\n",
       " 'take': 19,\n",
       " 'here': 19,\n",
       " 'open': 19,\n",
       " 'put': 19,\n",
       " 'got': 19,\n",
       " 'along': 18,\n",
       " 'group': 18,\n",
       " 'might': 18,\n",
       " 'thick': 18,\n",
       " 'wire': 18,\n",
       " 'several': 18,\n",
       " 'night': 18,\n",
       " 'live': 18,\n",
       " 'spring': 18,\n",
       " 'present': 18,\n",
       " 'honor': 18,\n",
       " 'order': 18,\n",
       " 'children': 18,\n",
       " 'presented': 18,\n",
       " 'dog': 18,\n",
       " 'very': 18,\n",
       " 'such': 18,\n",
       " 'around': 17,\n",
       " 'curiosity': 17,\n",
       " 'man': 17,\n",
       " 'let': 17,\n",
       " 'tell': 17,\n",
       " 'three': 17,\n",
       " 'old': 17,\n",
       " 'roll': 16,\n",
       " 'kept': 16,\n",
       " 'wore': 16,\n",
       " 'fill': 16,\n",
       " 'give': 16,\n",
       " 'save': 16,\n",
       " 'frequently': 16,\n",
       " 'times': 16,\n",
       " 'easy': 16,\n",
       " 'ever': 16,\n",
       " 'before': 16,\n",
       " 'almost': 16,\n",
       " 'child': 16,\n",
       " 'price': 16,\n",
       " 'once': 16,\n",
       " 'feet': 15,\n",
       " 'rarely': 15,\n",
       " 'without': 15,\n",
       " 'tube': 15,\n",
       " 'eight': 15,\n",
       " 'freely': 15,\n",
       " 'eating': 15,\n",
       " 'going': 15,\n",
       " 'sure': 15,\n",
       " 'again': 15,\n",
       " 'think': 15,\n",
       " 'left': 15,\n",
       " 'morning': 15,\n",
       " 'extra': 15,\n",
       " 'traffic': 15,\n",
       " 'men': 15,\n",
       " 'red': 15,\n",
       " 'own': 15,\n",
       " 'available': 15,\n",
       " 'assume': 15,\n",
       " 'museum': 15,\n",
       " 'edge': 15,\n",
       " 'instead': 15,\n",
       " 'shoes': 15,\n",
       " 'worked': 15,\n",
       " 'birthday': 15,\n",
       " 'gave': 15,\n",
       " 'maybe': 15,\n",
       " 'doctor': 15,\n",
       " 'watch': 15,\n",
       " 'store': 15,\n",
       " 'gift': 15,\n",
       " 'critical': 14,\n",
       " 'appreciated': 14,\n",
       " 'occurs': 14,\n",
       " 'academic': 14,\n",
       " 'aptitude': 14,\n",
       " 'government': 14,\n",
       " 'toothpaste': 14,\n",
       " 'outdoors': 14,\n",
       " 'social': 14,\n",
       " 'wealth': 14,\n",
       " 'essay': 14,\n",
       " 'turquoise': 14,\n",
       " 'suitable': 14,\n",
       " 'shellfish': 14,\n",
       " 'redwoods': 14,\n",
       " 'looked': 14,\n",
       " 'postponed': 14,\n",
       " 'speech': 14,\n",
       " 'elm': 14,\n",
       " 'forest': 14,\n",
       " 'examples': 14,\n",
       " \"we'll\": 14,\n",
       " 'black': 14,\n",
       " 'church': 14,\n",
       " 'muskrat': 14,\n",
       " 'geological': 14,\n",
       " 'instructions': 14,\n",
       " 'subject': 14,\n",
       " 'enjoy': 14,\n",
       " 'attitude': 14,\n",
       " 'draw': 14,\n",
       " 'moisture': 14,\n",
       " 'files': 14,\n",
       " 'breakfast': 14,\n",
       " 'coffee': 14,\n",
       " 'steep': 14,\n",
       " 'cats': 14,\n",
       " 'enter': 14,\n",
       " 'george': 14,\n",
       " 'alimony': 14,\n",
       " 'shone': 14,\n",
       " 'cut': 14,\n",
       " 'people': 14,\n",
       " 'hours': 14,\n",
       " 'disappeared': 14,\n",
       " 'lots': 14,\n",
       " 'participate': 14,\n",
       " 'fruit': 14,\n",
       " 'longer': 14,\n",
       " 'gently': 14,\n",
       " 'dessert': 14,\n",
       " 'parties': 14,\n",
       " 'buy': 14,\n",
       " 'thinks': 14,\n",
       " 'costumes': 14,\n",
       " 'colorful': 14,\n",
       " 'patient': 14,\n",
       " 'graph': 14,\n",
       " 'sculpture': 14,\n",
       " 'however': 14,\n",
       " 'yet': 14,\n",
       " 'box': 14,\n",
       " 'ancient': 14,\n",
       " 'bob': 14,\n",
       " 'rewarded': 14,\n",
       " 'came': 14,\n",
       " 'splinter': 14,\n",
       " 'hallway': 14,\n",
       " 'mean': 13,\n",
       " 'set': 13,\n",
       " 'become': 13,\n",
       " 'house': 13,\n",
       " 'really': 13,\n",
       " 'plan': 13,\n",
       " 'data': 13,\n",
       " 'hair': 13,\n",
       " 'lost': 13,\n",
       " 'across': 13,\n",
       " \"you'll\": 13,\n",
       " 'teeth': 12,\n",
       " 'next': 12,\n",
       " 'women': 12,\n",
       " 'rock': 12,\n",
       " 'students': 12,\n",
       " 'results': 12,\n",
       " 'system': 12,\n",
       " 'number': 12,\n",
       " 'himself': 12,\n",
       " 'head': 12,\n",
       " 'under': 12,\n",
       " 'light': 11,\n",
       " 'change': 11,\n",
       " 'face': 11,\n",
       " 'say': 11,\n",
       " 'nearly': 11,\n",
       " 'goes': 11,\n",
       " 'became': 11,\n",
       " 'value': 11,\n",
       " 'needed': 11,\n",
       " 'milk': 11,\n",
       " 'soon': 11,\n",
       " 'right': 11,\n",
       " 'work': 11,\n",
       " 'possible': 11,\n",
       " 'state': 11,\n",
       " \"you're\": 11,\n",
       " 'experience': 11,\n",
       " 'course': 11,\n",
       " 'walk': 11,\n",
       " 'trouble': 11,\n",
       " 'move': 11,\n",
       " 'where': 11,\n",
       " 'clay': 11,\n",
       " 'evidence': 11,\n",
       " 'try': 11,\n",
       " 'day': 11,\n",
       " 'play': 11,\n",
       " 'door': 11,\n",
       " 'deal': 11,\n",
       " 'four': 11,\n",
       " 'moment': 11,\n",
       " 'last': 11,\n",
       " 'until': 11,\n",
       " 'job': 11,\n",
       " 'equipment': 10,\n",
       " 'takes': 10,\n",
       " 'twice': 10,\n",
       " 'film': 10,\n",
       " 'thermometer': 10,\n",
       " 'poor': 10,\n",
       " 'forces': 10,\n",
       " 'site': 10,\n",
       " 'roof': 10,\n",
       " 'action': 10,\n",
       " 'word': 10,\n",
       " 'way': 10,\n",
       " 'begin': 10,\n",
       " 'serve': 10,\n",
       " 'talk': 10,\n",
       " 'cost': 10,\n",
       " 'answered': 10,\n",
       " 'although': 10,\n",
       " 'line': 10,\n",
       " 'woman': 10,\n",
       " 'met': 10,\n",
       " 'public': 10,\n",
       " 'things': 10,\n",
       " 'sweet': 10,\n",
       " 'common': 10,\n",
       " 'full': 10,\n",
       " 'farm': 10,\n",
       " 'tax': 10,\n",
       " 'club': 10,\n",
       " 'lines': 10,\n",
       " 'nine': 10,\n",
       " 'process': 10,\n",
       " 'bright': 10,\n",
       " \"one's\": 10,\n",
       " 'horse': 10,\n",
       " 'requires': 10,\n",
       " 'quite': 10,\n",
       " 'makes': 10,\n",
       " 'progress': 10,\n",
       " 'third': 10,\n",
       " 'warm': 10,\n",
       " 'want': 10,\n",
       " 'marine': 10,\n",
       " 'life': 10,\n",
       " 'run': 10,\n",
       " 'hung': 10,\n",
       " 'proper': 9,\n",
       " 'week': 9,\n",
       " 'felt': 9,\n",
       " 'rare': 9,\n",
       " 'voice': 9,\n",
       " 'gives': 9,\n",
       " 'wound': 9,\n",
       " 'miles': 9,\n",
       " 'tiny': 9,\n",
       " 'below': 9,\n",
       " 'camp': 9,\n",
       " 'received': 9,\n",
       " 'cannot': 9,\n",
       " 'nice': 9,\n",
       " 'emphasized': 9,\n",
       " 'success': 9,\n",
       " 'beds': 9,\n",
       " 'immediate': 9,\n",
       " 'trees': 9,\n",
       " 'crooked': 9,\n",
       " 'carefully': 9,\n",
       " 'positive': 9,\n",
       " 'features': 9,\n",
       " 'theory': 9,\n",
       " 'outer': 9,\n",
       " 'interior': 9,\n",
       " 'attacked': 9,\n",
       " 'snow': 9,\n",
       " 'grow': 9,\n",
       " 'local': 9,\n",
       " 'pleasure': 9,\n",
       " 'impossible': 9,\n",
       " 'needle': 9,\n",
       " 'street': 9,\n",
       " 'lot': 9,\n",
       " 'rose': 9,\n",
       " 'stayed': 9,\n",
       " 'cows': 9,\n",
       " \"man's\": 9,\n",
       " 'dry': 9,\n",
       " 'according': 9,\n",
       " 'others': 9,\n",
       " 'corner': 9,\n",
       " \"couldn't\": 9,\n",
       " 'measured': 9,\n",
       " 'barbed': 9,\n",
       " 'field': 9,\n",
       " 'remove': 9,\n",
       " 'events': 9,\n",
       " 'hat': 9,\n",
       " 'policy': 9,\n",
       " 'larger': 9,\n",
       " 'getting': 9,\n",
       " 'finish': 9,\n",
       " 'development': 9,\n",
       " 'psychological': 9,\n",
       " 'acts': 9,\n",
       " 'difficult': 9,\n",
       " 'eggs': 9,\n",
       " 'regular': 9,\n",
       " 'completely': 9,\n",
       " 'muscles': 9,\n",
       " 'onto': 9,\n",
       " 'hired': 9,\n",
       " 'lay': 9,\n",
       " 'rain': 9,\n",
       " 'values': 9,\n",
       " 'name': 9,\n",
       " 'thought': 9,\n",
       " 'destroy': 9,\n",
       " 'waiting': 9,\n",
       " 'thin': 9,\n",
       " 'clearly': 9,\n",
       " 'shadow': 9,\n",
       " 'quality': 9,\n",
       " 'teach': 9,\n",
       " 'study': 9,\n",
       " 'flew': 9,\n",
       " 'thing': 9,\n",
       " 'catch': 8,\n",
       " 'emperor': 8,\n",
       " 'permanent': 8,\n",
       " 'maintenance': 8,\n",
       " 'vapor': 8,\n",
       " 'programs': 8,\n",
       " 'clear': 8,\n",
       " 'power': 8,\n",
       " 'guarantees': 8,\n",
       " 'sought': 8,\n",
       " 'citizenship': 8,\n",
       " 'steps': 8,\n",
       " 'reading': 8,\n",
       " 'quick': 8,\n",
       " 'hit': 8,\n",
       " 'due': 8,\n",
       " 'visual': 8,\n",
       " 'execute': 8,\n",
       " 'dispute': 8,\n",
       " 'view': 8,\n",
       " 'shock': 8,\n",
       " 'cured': 8,\n",
       " 'doctors': 8,\n",
       " 'drugs': 8,\n",
       " 'bowl': 8,\n",
       " 'hear': 8,\n",
       " 'music': 8,\n",
       " 'angry': 8,\n",
       " 'engineering': 8,\n",
       " 'meet': 8,\n",
       " 'surely': 8,\n",
       " 'finds': 8,\n",
       " 'county': 8,\n",
       " 'cottage': 8,\n",
       " 'careful': 8,\n",
       " 'sudden': 8,\n",
       " 'approach': 8,\n",
       " 'answers': 8,\n",
       " 'rise': 8,\n",
       " 'worship': 8,\n",
       " 'alone': 8,\n",
       " 'tests': 8,\n",
       " 'agree': 8,\n",
       " 'leaves': 8,\n",
       " 'cat': 8,\n",
       " 'correct': 8,\n",
       " 'dwarf': 8,\n",
       " 'valley': 8,\n",
       " 'dish': 8,\n",
       " 'popularity': 8,\n",
       " 'cooking': 8,\n",
       " 'wild': 8,\n",
       " 'build': 8,\n",
       " 'beverage': 8,\n",
       " 'plant': 8,\n",
       " 'project': 8,\n",
       " 'simple': 8,\n",
       " 'broke': 8,\n",
       " 'farmers': 8,\n",
       " 'oats': 8,\n",
       " 'break': 8,\n",
       " 'prepared': 8,\n",
       " 'sauce': 8,\n",
       " 'coat': 8,\n",
       " 'paper': 8,\n",
       " 'count': 8,\n",
       " 'thread': 8,\n",
       " 'education': 8,\n",
       " 'flag': 8,\n",
       " 'musical': 8,\n",
       " 'charge': 8,\n",
       " 'grown': 8,\n",
       " 'jungle': 8,\n",
       " 'straight': 8,\n",
       " 'ahead': 8,\n",
       " 'conditions': 8,\n",
       " 'smelled': 8,\n",
       " 'proof': 8,\n",
       " 'books': 8,\n",
       " 'gold': 8,\n",
       " 'capable': 8,\n",
       " 'fails': 8,\n",
       " 'exclusive': 8,\n",
       " 'contained': 8,\n",
       " 'national': 8,\n",
       " 'intelligence': 8,\n",
       " 'variety': 8,\n",
       " 'told': 8,\n",
       " 'garbage': 8,\n",
       " 'lack': 8,\n",
       " 'grievances': 8,\n",
       " 'cow': 8,\n",
       " 'gone': 8,\n",
       " 'growing': 8,\n",
       " 'went': 8,\n",
       " 'feelings': 8,\n",
       " 'performance': 8,\n",
       " 'handed': 8,\n",
       " 'surrounded': 8,\n",
       " 'sea': 8,\n",
       " 'relaxed': 8,\n",
       " 'ideal': 8,\n",
       " 'animals': 8,\n",
       " 'constantly': 8,\n",
       " 'picked': 8,\n",
       " 'choices': 8,\n",
       " 'roast': 8,\n",
       " 'foreign': 8,\n",
       " 'activities': 8,\n",
       " 'sitting': 8,\n",
       " 'remained': 8,\n",
       " 'friends': 8,\n",
       " 'display': 8,\n",
       " 'atheists': 8,\n",
       " 'buying': 8,\n",
       " 'either': 8,\n",
       " 'slipped': 8,\n",
       " 'surgeon': 8,\n",
       " 'operation': 8,\n",
       " 'damage': 8,\n",
       " 'ignored': 8,\n",
       " 'points': 8,\n",
       " 'famous': 8,\n",
       " 'gained': 8,\n",
       " 'uses': 8,\n",
       " 'comes': 8,\n",
       " 'wasp': 8,\n",
       " 'caught': 8,\n",
       " 'diagnosis': 8,\n",
       " 'worried': 8,\n",
       " 'ready': 8,\n",
       " 'violence': 8,\n",
       " 'chose': 8,\n",
       " 'cartoons': 8,\n",
       " 'exist': 8,\n",
       " 'fixed': 8,\n",
       " 'thoroughly': 8,\n",
       " 'activity': 8,\n",
       " 'discussions': 8,\n",
       " 'attention': 8,\n",
       " 'technical': 8,\n",
       " 'tongue': 8,\n",
       " 'spherical': 8,\n",
       " 'stems': 8,\n",
       " 'required': 8,\n",
       " 'land': 8,\n",
       " 'audience': 8,\n",
       " 'ballet': 8,\n",
       " 'behind': 8,\n",
       " 'latest': 8,\n",
       " 'team': 8,\n",
       " 'jokes': 8,\n",
       " 'remember': 8,\n",
       " 'identical': 8,\n",
       " 'advertising': 8,\n",
       " 'verse': 8,\n",
       " 'changes': 8,\n",
       " 'check': 8,\n",
       " 'chamber': 8,\n",
       " 'loved': 8,\n",
       " 'doll': 8,\n",
       " 'microorganisms': 8,\n",
       " 'poisonous': 8,\n",
       " 'sing': 8,\n",
       " 'news': 8,\n",
       " 'building': 8,\n",
       " 'names': 8,\n",
       " 'five': 8,\n",
       " 'lives': 8,\n",
       " 'lively': 8,\n",
       " 'food': 8,\n",
       " 'tapestry': 8,\n",
       " 'wall': 8,\n",
       " 'major': 8,\n",
       " 'failure': 8,\n",
       " 'chop': 8,\n",
       " 'pair': 8,\n",
       " 'oak': 8,\n",
       " 'table': 8,\n",
       " 'cab': 8,\n",
       " 'repainting': 8,\n",
       " 'opaque': 8,\n",
       " 'leather': 8,\n",
       " 'yards': 8,\n",
       " 'contributed': 8,\n",
       " 'wood': 8,\n",
       " 'cement': 8,\n",
       " 'little': 8,\n",
       " 'naive': 8,\n",
       " 'temper': 7,\n",
       " 'records': 7,\n",
       " 'meeting': 7,\n",
       " 'adjourned': 7,\n",
       " 'tim': 7,\n",
       " 'sheila': 7,\n",
       " 'cyclical': 7,\n",
       " 'compile': 7,\n",
       " 'pronunciation': 7,\n",
       " 'steve': 7,\n",
       " 'collects': 7,\n",
       " 'novel': 7,\n",
       " 'coins': 7,\n",
       " 'outage': 7,\n",
       " 'diploma': 7,\n",
       " 'authorization': 7,\n",
       " 'oyster': 7,\n",
       " \"nora's\": 7,\n",
       " 'plate': 7,\n",
       " 'shawn': 7,\n",
       " 'goose': 7,\n",
       " 'squeezed': 7,\n",
       " 'bottom': 7,\n",
       " 'raisins': 7,\n",
       " 'porch': 7,\n",
       " 'drunkard': 7,\n",
       " 'outcast': 7,\n",
       " 'eyestrain': 7,\n",
       " 'murky': 7,\n",
       " 'lagoon': 7,\n",
       " 'crab': 7,\n",
       " 'challenged': 7,\n",
       " 'stab': 7,\n",
       " 'vanquished': 7,\n",
       " 'upgrade': 7,\n",
       " 'status': 7,\n",
       " 'reflect': 7,\n",
       " 'true': 7,\n",
       " 'haunted': 7,\n",
       " 'outstanding': 7,\n",
       " 'audio': 7,\n",
       " 'effects': 7,\n",
       " 'icicles': 7,\n",
       " 'lawyer': 7,\n",
       " 'appointed': 7,\n",
       " 'toddler': 7,\n",
       " 'clamshell': 7,\n",
       " 'cooperation': 7,\n",
       " 'understanding': 7,\n",
       " 'alleviate': 7,\n",
       " 'far': 7,\n",
       " 'kayak': 7,\n",
       " 'bayou': 7,\n",
       " 'undeniably': 7,\n",
       " 'reflects': 7,\n",
       " 'ably': 7,\n",
       " \"i'll\": 7,\n",
       " 'scoop': 7,\n",
       " 'exotic': 7,\n",
       " 'purple': 7,\n",
       " 'sherbet': 7,\n",
       " 'shell': 7,\n",
       " 'shrapnel': 7,\n",
       " 'therapy': 7,\n",
       " 'prescribe': 7,\n",
       " 'mango': 7,\n",
       " 'papaya': 7,\n",
       " 'sleigh': 7,\n",
       " 'bells': 7,\n",
       " 'ringing': 7,\n",
       " 'rhythm': 7,\n",
       " 'adult': 7,\n",
       " 'male': 7,\n",
       " \"baboon's\": 7,\n",
       " 'giant': 7,\n",
       " 'glistening': 7,\n",
       " 'mediocrity': 7,\n",
       " 'coexist': 7,\n",
       " 'al': 7,\n",
       " 'joint': 7,\n",
       " 'appointment': 7,\n",
       " 'biology': 7,\n",
       " 'departments': 7,\n",
       " 'stag': 7,\n",
       " 'fawn': 7,\n",
       " 'official': 7,\n",
       " 'deadline': 7,\n",
       " 'girl': 7,\n",
       " 'westchester': 7,\n",
       " 'york': 7,\n",
       " 'sermon': 7,\n",
       " 'affirmative': 7,\n",
       " 'chives': 7,\n",
       " 'delicious': 7,\n",
       " 'celebrate': 7,\n",
       " \"brother's\": 7,\n",
       " 'spotted': 7,\n",
       " 'hyenas': 7,\n",
       " 'jaguars': 7,\n",
       " 'safari': 7,\n",
       " 'plow': 7,\n",
       " 'flower': 7,\n",
       " 'symposium': 7,\n",
       " 'overwhelmed': 7,\n",
       " 'dutch': 7,\n",
       " 'disease': 7,\n",
       " 'misprint': 7,\n",
       " 'provoked': 7,\n",
       " 'disclaimer': 7,\n",
       " 'departure': 7,\n",
       " 'shocked': 7,\n",
       " 'cast': 7,\n",
       " 'interview': 7,\n",
       " 'statuesque': 7,\n",
       " 'composure': 7,\n",
       " 'alfalfa': 7,\n",
       " 'healthy': 7,\n",
       " 'avalanche': 7,\n",
       " 'triggered': 7,\n",
       " 'minor': 7,\n",
       " 'earthquake': 7,\n",
       " 'welcome': 7,\n",
       " 'anything': 7,\n",
       " 'publicity': 7,\n",
       " 'notoriety': 7,\n",
       " 'pathological': 7,\n",
       " 'straightforward': 7,\n",
       " 'rhubarb': 7,\n",
       " \"rachel's\": 7,\n",
       " 'biblical': 7,\n",
       " 'scholars': 7,\n",
       " 'argue': 7,\n",
       " 'history': 7,\n",
       " 'clasp': 7,\n",
       " 'screw': 7,\n",
       " 'peeling': 7,\n",
       " 'spray': 7,\n",
       " 'artists': 7,\n",
       " 'exchanged': 7,\n",
       " 'autographs': 7,\n",
       " 'smiths': 7,\n",
       " 'start': 7,\n",
       " 'cartoon': 7,\n",
       " 'tadpole': 7,\n",
       " 'occasionally': 7,\n",
       " 'blues': 7,\n",
       " 'survive': 7,\n",
       " 'giraffes': 7,\n",
       " 'zoos': 7,\n",
       " 'shorten': 7,\n",
       " 'skirt': 7,\n",
       " 'joyce': 7,\n",
       " 'scholastic': 7,\n",
       " 'judged': 7,\n",
       " 'standardized': 7,\n",
       " 'intelligible': 7,\n",
       " 'smash': 7,\n",
       " 'lightbulbs': 7,\n",
       " 'cash': 7,\n",
       " 'diminish': 7,\n",
       " 'continental': 7,\n",
       " 'drift': 7,\n",
       " 'execution': 7,\n",
       " 'crucial': 7,\n",
       " 'courier': 7,\n",
       " 'lodge': 7,\n",
       " 'yearly': 7,\n",
       " 'celebrates': 7,\n",
       " 'calf': 7,\n",
       " 'born': 7,\n",
       " 'prowler': 7,\n",
       " 'ski': 7,\n",
       " 'mask': 7,\n",
       " 'disguise': 7,\n",
       " 'knew': 7,\n",
       " 'being': 7,\n",
       " 'dad': 7,\n",
       " 'bidding': 7,\n",
       " 'trespassing': 7,\n",
       " 'forbidden': 7,\n",
       " 'penalty': 7,\n",
       " 'best': 7,\n",
       " 'players': 7,\n",
       " 'bleu': 7,\n",
       " 'victor': 7,\n",
       " 'prefers': 7,\n",
       " 'swiss': 7,\n",
       " 'unbeatable': 7,\n",
       " 'showers': 7,\n",
       " 'yes': 7,\n",
       " 'creole': 7,\n",
       " 'curry': 7,\n",
       " 'eyedrops': 7,\n",
       " 'tears': 7,\n",
       " 'shredded': 7,\n",
       " 'primitive': 7,\n",
       " 'tribes': 7,\n",
       " 'upbeat': 7,\n",
       " 'cory': 7,\n",
       " 'determination': 7,\n",
       " 'desires': 7,\n",
       " 'informative': 7,\n",
       " 'paragraph': 7,\n",
       " 'taxicab': 7,\n",
       " 'jam': 7,\n",
       " 'etiquette': 7,\n",
       " 'mandates': 7,\n",
       " 'compliance': 7,\n",
       " 'existing': 7,\n",
       " 'regulations': 7,\n",
       " 'fjords': 7,\n",
       " 'flurries': 7,\n",
       " 'atypical': 7,\n",
       " 'ralph': 7,\n",
       " 'snapper': 7,\n",
       " 'lemon': 7,\n",
       " 'original': 7,\n",
       " 'forgery': 7,\n",
       " 'willowy': 7,\n",
       " 'apples': 7,\n",
       " 'ices': 7,\n",
       " 'drugstore': 7,\n",
       " 'charged': 7,\n",
       " 'illegally': 7,\n",
       " 'dispensing': 7,\n",
       " 'tranquilizers': 7,\n",
       " 'irish': 7,\n",
       " 'youngsters': 7,\n",
       " 'kippers': 7,\n",
       " 'eastern': 7,\n",
       " 'coast': 7,\n",
       " 'pure': 7,\n",
       " 'excitement': 7,\n",
       " 'vietnamese': 7,\n",
       " 'cuisine': 7,\n",
       " 'exquisite': 7,\n",
       " 'create': 7,\n",
       " 'illuminating': 7,\n",
       " 'teaspoons': 7,\n",
       " 'soysauce': 7,\n",
       " 'seamstresses': 7,\n",
       " 'attach': 7,\n",
       " 'zippers': 7,\n",
       " 'thimble': 7,\n",
       " 'legislature': 7,\n",
       " 'judge': 7,\n",
       " 'employee': 7,\n",
       " 'layoffs': 7,\n",
       " 'coincided': 7,\n",
       " \"company's\": 7,\n",
       " 'reorganization': 7,\n",
       " 'aggressive': 7,\n",
       " 'policeman': 7,\n",
       " 'thoughtless': 7,\n",
       " 'motorists': 7,\n",
       " 'bagpipes': 7,\n",
       " 'bongos': 7,\n",
       " 'instruments': 7,\n",
       " 'auburn': 7,\n",
       " 'reminded': 7,\n",
       " 'autumn': 7,\n",
       " 'gorgeous': 7,\n",
       " 'butterfly': 7,\n",
       " 'nectar': 7,\n",
       " 'choosing': 7,\n",
       " \"bride's\": 7,\n",
       " \"maids'\": 7,\n",
       " 'gowns': 7,\n",
       " 'slopes': 7,\n",
       " 'temperate': 7,\n",
       " 'zones': 7,\n",
       " 'corsage': 7,\n",
       " 'angora': 7,\n",
       " 'furrier': 7,\n",
       " 'siamese': 7,\n",
       " 'nonprofit': 7,\n",
       " 'organizations': 7,\n",
       " 'frequent': 7,\n",
       " 'fund': 7,\n",
       " 'raisers': 7,\n",
       " 'seeking': 7,\n",
       " \"barb's\": 7,\n",
       " 'bracelet': 7,\n",
       " 'graduation': 7,\n",
       " 'burglar': 7,\n",
       " 'law': 7,\n",
       " 'tugboats': 7,\n",
       " 'hauling': 7,\n",
       " 'loads': 7,\n",
       " 'allowance': 7,\n",
       " 'force': 7,\n",
       " 'documents': 7,\n",
       " 'locked': 7,\n",
       " ...}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(words_list.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3596fcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2210 9400 spring\r\n",
      "9400 16887 street\r\n",
      "16887 20386 is\r\n",
      "20386 24680 straight\r\n",
      "24680 31040 ahead\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./data/data/TRAIN/DR1/MRAI0/SX72.WRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "12d1c528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,UklGRt4EAABXQVZFZm10IBAAAAABAAEAgD4AAAB9AAACABAAZGF0YboEAABeAg8LyiCEFoEHDfwcByIFm/+b/0P7HAfq9q751O1g4jbfYOKC55XhU+ZG6u7lAeBm4Dru4elJ2d7aF+lv7TDhSdlJ2RrYf9ga2Fnk2+uC54LnfOnh6YLnMOGc3wHgsujU7f3w2+uJ5bLo4emJ5e7lWeSC5xfpb+338rv1kvLe+pcQPizfSXppGHizd+VnvGQ+bGdvUWYbZzhu+3DDYt9JzS/AE675q+rb69Tt+uFd0+HJB74ntLKoj6O5ptWtnL9W1dHeNt+i3WbgfOl5+pcQNR9RJkUqujXWPKA9KzKXMLo1pzunOzs9dzr2Mqoq+SHDIpof4xg/DCIFm//q9vTju9XC09jcAeBs3qLdKuO45hfpY/FD+4cFewnAE2QgDyujLFgkoB3WHNYcoB3WHBIaLBJ0C70EB/679W/tvuRm4MXiU+a45o/jNt+i3Tbfy+C45hDrBO+S8ur2Q/t5+rX3IPYa+KL98wPzA2z+GviS8tvrYOJ52pnQfMm/xE3IM9Dr1vHUOs4z0P7Q99LC01DXnN8B4Jzfc9wa2JLSmdCG1vrhBO9/+A38VvUz8DPwf/gvAQ38/fC79bX3cvyY8O7lNt/F4o/jEOv38soAvSQeVpZwqWqKVBhY0m3/f+90g3bGcQ5rQVuqSlszpxtJ+YLnOu6u+a75pexd04PH9MMdx/7QGtiv2TDhQOxQ9w38hfYz8IX2jgMlFJQhtya3Jvkh0B7/H7AoAi8JLeYnWCTsJTUfaA89/df8RQpuDRYJygAN/MHzCu1N6DruXPN/+JQBSwgWCeYHlAGOA+wFwBNxHC8h8yOUITsd1hwZGOkWSBnWHDsdcRy6FUUKDfxj8UDs5+dA7Artb+3U7Ubq9ONZ5Fnkduv38kn51/zR/gf+0f4H/qL9B/5eAr0EtwZeAtf8u/Vp7x3nxeIB4Njc8dQ6zonFlsHox1DXgucg9t766vaY8KXsuOYj5U3oae8g9lb1/fCr6mbgB95D29He1O279a75Q/uu+ffy4emV4Ynlzu95+tf83vo67u7lleGJ5fTjpeyF9iD2LfKM9K75DfwU+j39hwWdDt0aoyzjOH04lzBnLx82+UHZS2dPCE3DQnE8WzMVKeMYlxAiBdf8jgM4DvwQtwau+WPxY/Et8oz0DfwAAIcFDwt0C0UKlAFD+3/4bP6kDK0Z4xgfFn4YQhsGHv8fdxpOF5ES8BRrHv8fsxeBBzb/ewnNDzgOtwbKANf8bP75AVIGwwJlAJv/IgWwCHQLdAt0Cw8LaA9+GHEcGRg4DuAJRQqHBS8B1/x5+n/46vZ/+EP7u/Xb6+Hpn+6u+d76UPe191D3IPbI8c7vae9p79vrOu798M7vfOnF4mze2NwH3qjbUNct0v7QwtP64bX32QuREtkLZQBJ+eT4jPQn9CD25Pga+C3yHecH3rXX/tDC09HeCu1y/EP7bP7R/vfyF+mC57v1FgluDcMCov1Q9wrtvuQd52/tpewt8qj7jgPKAJv/VvVv7YX2IgWdDj8Mbg3TDb0Etffk+C8BvQTsBdMNQhugHdYc3RpVFVUVsxegHVgkFSl0K3op1hz8EFgE7AUDDz8MUgb8EFsThwVy/GUAPwwJDZ0O\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, sr = sf.read(\"./data/data/TRAIN/DR1/MRAI0/SX72.WAV.wav\", dtype='float32')\n",
    "IPython.display.Audio(data=s[31040 :31645    ], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d98eca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2vec2featurize(model, source, feature_name):\n",
    "    \"\"\"\n",
    "    Inference function of pretrained wav2vec2 to extract intermediate representations\n",
    "    Ref: https://github.com/pytorch/fairseq/blob/89ec6e7efff867d258947acafc57189b257212d0/fairseq/models/wav2vec/wav2vec2.py\n",
    "    \"\"\"\n",
    "    assert feature_name in ['cnn_output', 'vq', 'projected_vq', 'encoder_output', 'context_vector']\n",
    "    cnn_features = model.feature_extractor(source)\n",
    "\n",
    "    cnn_features = cnn_features.transpose(1, 2)\n",
    "    \n",
    "    if feature_name == 'cnn_output':\n",
    "        return cnn_features.squeeze(0)\n",
    "    \n",
    "    features = model.layer_norm(cnn_features)\n",
    "\n",
    "    if model.quantizer: # this is not None in pretrained w2v\n",
    "        q = model.quantizer(features, produce_targets=False)\n",
    "        quantized_features = q[\"x\"]\n",
    "        if feature_name == 'vq':\n",
    "            return quantized_features.squeeze(0)\n",
    "        projected_quantized_features = model.project_q(quantized_features)\n",
    "        if feature_name == 'projected_vq':\n",
    "            return projected_quantized_features.squeeze(0)\n",
    "\n",
    "    if model.post_extract_proj is not None: # this is not None in pretrained w2v\n",
    "        features = model.post_extract_proj(features)\n",
    "\n",
    "    if model.input_quantizer is not None: # this is None in pretrained w2v\n",
    "        q = model.input_quantizer(features, produce_targets=False)\n",
    "        features = q['x']\n",
    "        features = model.project_inp(features)\n",
    "\n",
    "    encoder_outputs, encoder_layers_features = model.encoder(features, padding_mask=None, layer=None)\n",
    "    \n",
    "    if feature_name == 'encoder_output':\n",
    "        return encoder_outputs.squeeze(0)\n",
    "\n",
    "    context_vectors = model.final_proj(encoder_outputs)\n",
    "\n",
    "    return context_vectors.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49249bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0458,  1.0363, -0.3802,  ..., -1.2763,  0.5118, -0.3924],\n",
       "        [-0.7767, -0.6042, -0.1070,  ..., -0.0194, -0.7107, -1.8827]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav2vec2featurize(wav2vec2, torch.tensor(s[39561:40313]).unsqueeze(0), 'encoder_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "003d86e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" >\n",
       "                    <source src=\"data:audio/wav;base64,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\" type=\"audio/wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, sr = sf.read(\"./data/data/TRAIN/DR1/FCJF0/SA1.WAV.wav\", dtype='float32')\n",
    "IPython.display.Audio(data=s[4559:5723], rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ead6f5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Model(\n",
       "  (feature_extractor): ConvFeatureExtractionModel(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        (3): GELU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "      (6): Sequential(\n",
       "        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        (1): Dropout(p=0.0, inplace=False)\n",
       "        (2): GELU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "  (dropout_input): Dropout(p=0.1, inplace=False)\n",
       "  (dropout_features): Dropout(p=0.1, inplace=False)\n",
       "  (quantizer): GumbelVectorQuantizer(\n",
       "    (weight_proj): Linear(in_features=512, out_features=640, bias=True)\n",
       "  )\n",
       "  (project_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (encoder): TransformerEncoder(\n",
       "    (pos_conv): Sequential(\n",
       "      (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (1): SamePad()\n",
       "      (2): GELU()\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): TransformerSentenceEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (final_proj): Linear(in_features=768, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav2vec2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
